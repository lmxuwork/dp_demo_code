## Review
- 注意点，学习步长的大小与超参的初始值，否则预测会成一条直线，可以多次随机训练，数据样本多会好很多。
- 增加Relu激活函数
  - 增加网络的非线性
  - 小于0部分为0，大于0部分才有值，可以减少过拟合。
  - ...
- 学习率
  - 学习率过大，会导致迭代发散
  - 过小，会导致收敛变慢

## 重点
- 概率与统计
  - 期望(mean):
    - 连续类型: $\mathbb{E}(x)=\int_{-\infty}^{+\infty}xp(x)dx$
    - 离散类型: $\mathbb{E}(x)=\sum_i x_i p(x_i)=\mu(x)$
    - 概率应当是研究样本所得
  - 统计量: 样本均值
    - $\bar{x} = \sum_i ^n\frac{x_i}{N}$
    - $x_i$是样本
  - 方差
    - $Var(x)=\int_{-\infty}^{+\infty}(x-\mu)^2p(x)dx$
    - 方差无偏估计: $\frac{\sum_i(x_i-\bar{x})^2}{N-1}$
    - 标准差: $\sigma=\sqrt{Var(x)}$
      - 标准差反应组内个体间的离散程度
  - 熵
    - 信息量用来衡量某个事件的不确定性，熵用来衡量系统（所有事件）的不确定性
      - $H(x)=-\sum_{i=1}^n p(x_i)log(p(x_i))$
      - $p(x_i)$为事件$X=x_i$的概率，$-log(p(x_i))$为事件$X=x_i$的信息量
      - 熵是信息量的期望值，是一个随机变量不确定的度量，熵值越小，系统越稳定。
- 函数与优化
  - 梯度迭代算法，公式的推导
- 线性代数
  - 矩阵运算，SVD分解、仿射变换、特征值分解...